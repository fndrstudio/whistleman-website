---
phase: 05-seo-implementation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - index.html
  - services.html
  - portfolio.html
  - contact.html
  - portfolio/burgernshake.html
  - portfolio/oeuf.html
  - portfolio/locals.html
  - portfolio/linguini.html
  - portfolio/pazzi.html
  - portfolio/inner circle.html
  - portfolio/l'OUI.html
  - robots.txt
  - sitemap.xml
autonomous: true

must_haves:
  truths:
    - "Sharing any page on social media shows proper preview card with image, title, and description"
    - "robots.txt exists at site root and is valid"
    - "sitemap.xml exists at site root with all 11 pages listed"
  artifacts:
    - path: "index.html"
      provides: "OG and Twitter meta tags for homepage"
      contains: "og:image"
    - path: "robots.txt"
      provides: "Crawler directives"
      contains: "Sitemap:"
    - path: "sitemap.xml"
      provides: "Page listing for search engines"
      contains: "urlset"
  key_links:
    - from: "robots.txt"
      to: "sitemap.xml"
      via: "Sitemap directive"
      pattern: "Sitemap:.*sitemap.xml"
    - from: "*.html"
      to: "og:image"
      via: "Meta tag referencing image file"
      pattern: "og:image.*content="
---

<objective>
Add Open Graph and Twitter Card meta tags to all 11 HTML pages, and create robots.txt + sitemap.xml for search engine crawling.

Purpose: Make shared links display rich preview cards on social platforms (Facebook, LinkedIn, Twitter, WhatsApp) and ensure search engines can efficiently discover and index all pages.

Output: All HTML files with OG/Twitter meta tags, plus robots.txt and sitemap.xml at site root.
</objective>

<execution_context>
@/Users/thuijsmans/.claude/get-shit-done/workflows/execute-plan.md
@/Users/thuijsmans/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-seo-implementation/05-RESEARCH.md

# Current HTML structure
@index.html (for existing head structure)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add OG/Twitter meta tags to all pages</name>
  <files>
    index.html
    services.html
    portfolio.html
    contact.html
    portfolio/burgernshake.html
    portfolio/oeuf.html
    portfolio/locals.html
    portfolio/linguini.html
    portfolio/pazzi.html
    portfolio/inner circle.html
    portfolio/l'OUI.html
  </files>
  <action>
Add Open Graph and Twitter Card meta tags to each HTML file's `<head>` section, after the existing meta description tag.

For each page, add these meta tags with PAGE-SPECIFIC values:

```html
<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://whistlemanmedia.nl/{page-path}">
<meta property="og:title" content="{page-title}">
<meta property="og:description" content="{page-description}">
<meta property="og:image" content="https://whistlemanmedia.nl/assets/img/og-{page}.jpg">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="630">
<meta property="og:site_name" content="Whistleman Media">
<meta property="og:locale" content="en_US">

<!-- Twitter -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:title" content="{page-title}">
<meta name="twitter:description" content="{page-description}">
<meta name="twitter:image" content="https://whistlemanmedia.nl/assets/img/og-{page}.jpg">

<!-- Canonical URL -->
<link rel="canonical" href="https://whistlemanmedia.nl/{page-path}">
```

Page-specific values:

| Page | og:type | og:title | og:image reference |
|------|---------|----------|-------------------|
| index.html | website | We tell stories that build brands - Whistleman Media | og-home.jpg |
| services.html | website | Our Services - Whistleman Media | og-services.jpg |
| portfolio.html | website | Our Work - Whistleman Media | og-portfolio.jpg |
| contact.html | website | Contact Us - Whistleman Media | og-contact.jpg |
| portfolio/*.html | article | Case Study: {Client} - Whistleman Media | og-{client}.jpg |

For case studies, use `og:type` of "article" (not "website").

**IMPORTANT:**
- Use existing hero images as og:image sources. The actual OG images don't need to exist yet - reference them as `assets/img/og-{name}.jpg`. Creating the actual 1200x630 images is a manual design task.
- Keep existing meta description - use it for og:description and twitter:description
- Remove the `<meta name="keywords">` tag from all pages (deprecated since 2009, ignored by search engines)
- Each page MUST have unique og:title and og:description matching the page's actual content
  </action>
  <verify>
grep -c "og:image" *.html portfolio/*.html 2>/dev/null | grep -v ":0"
# Should show 11 files, each with at least 1 og:image tag

grep -c "twitter:card" *.html portfolio/*.html 2>/dev/null | grep -v ":0"
# Should show 11 files
  </verify>
  <done>
All 11 HTML pages have OG and Twitter meta tags with page-specific titles, descriptions, and image references. No duplicate meta content across pages. Keywords meta tag removed.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create robots.txt and sitemap.xml</name>
  <files>
    robots.txt
    sitemap.xml
  </files>
  <action>
Create robots.txt at site root with:

```
# Whistleman Media - robots.txt
# https://whistlemanmedia.nl/robots.txt

User-agent: *
Allow: /
Disallow: /cgi-bin/
Disallow: /.git/
Disallow: /errors/

# Sitemap Location
Sitemap: https://whistlemanmedia.nl/sitemap.xml
```

Create sitemap.xml at site root with all 11 pages:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://whistlemanmedia.nl/</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>1.0</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/services</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.9</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/contact</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.7</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/burgernshake</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/oeuf</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/locals</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/linguini</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/pazzi</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/inner-circle</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
  <url>
    <loc>https://whistlemanmedia.nl/portfolio/loui</loc>
    <lastmod>2026-02-06</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.8</priority>
  </url>
</urlset>
```

**Note:** URLs use clean paths without .html extensions (site uses .htaccess for URL rewriting). Handle special characters in filenames: "inner circle.html" becomes "inner-circle" and "l'OUI.html" becomes "loui" in URLs.
  </action>
  <verify>
# Check robots.txt exists and references sitemap
cat robots.txt | grep -i sitemap

# Check sitemap.xml is valid XML and has all pages
xmllint --noout sitemap.xml 2>&1 && echo "Valid XML"
grep -c "<loc>" sitemap.xml
# Should show 11 (one for each page)
  </verify>
  <done>
robots.txt exists at site root with crawler directives and sitemap reference. sitemap.xml exists with all 11 pages listed with proper URLs, lastmod dates, and priorities.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. **OG tags present on all pages:**
   ```bash
   for f in *.html portfolio/*.html; do
     echo "$f: $(grep -c 'og:image' "$f") OG tags"
   done
   ```

2. **No duplicate meta descriptions across pages:**
   ```bash
   grep -h 'og:description' *.html portfolio/*.html | sort | uniq -c | sort -n
   # Each description should appear only once
   ```

3. **robots.txt accessible:**
   ```bash
   cat robots.txt
   ```

4. **sitemap.xml valid:**
   ```bash
   xmllint --noout sitemap.xml && echo "Sitemap is valid XML"
   ```
</verification>

<success_criteria>
1. All 11 HTML files have OG meta tags (og:title, og:description, og:image, og:url)
2. All 11 HTML files have Twitter Card meta tags (twitter:card, twitter:title, twitter:description, twitter:image)
3. Each page has unique og:title and og:description (no copy-paste duplicates)
4. robots.txt exists at site root with Sitemap directive
5. sitemap.xml exists at site root with 11 URLs
6. sitemap.xml is valid XML (xmllint passes)
7. Keywords meta tag removed from all pages
</success_criteria>

<output>
After completion, create `.planning/phases/05-seo-implementation/05-01-SUMMARY.md`
</output>
